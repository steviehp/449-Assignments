{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"qeJ05csb_Vfu"},"source":["# **Main Goal: Create an CNN that can detect \"hot spots\" from thermal images**"]},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"aNooI79Ze7M3"}},{"cell_type":"markdown","metadata":{"id":"JO9kRfKHm6yz"},"source":["# **Get The Data**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VOA-Db63_MMb","executionInfo":{"status":"ok","timestamp":1672813942803,"user_tz":300,"elapsed":3862,"user":{"displayName":"Steven Nguyen","userId":"06336820862144147778"}},"outputId":"cf7891e1-c5d6-4d2c-bd74-1fe76a52b1cd"},"source":["#Import The Essentials\n","\n","#Import Modules\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras\n","\n","#Import Pillow Image Tools\n","import PIL\n","import PIL.Image\n","\n","#Display Version of TensorFlow\n","print(\"TensorFlow Version:\", tf.__version__)\n","\n","#Print Number of GPUs being Used\n","print(\"The Number of GPUs Available is: \", len(tf.config.list_physical_devices('GPU')))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow Version: 2.9.2\n","The Number of GPUs Available is:  1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":386},"id":"C91t1lJK_fFG","executionInfo":{"status":"error","timestamp":1672814004488,"user_tz":300,"elapsed":61690,"user":{"displayName":"Steven Nguyen","userId":"06336820862144147778"}},"outputId":"c2350459-c2da-4c29-df64-ff9b42d14e4f"},"source":["#Load The Dataset\n","\n","#Allow Google Colab to Access Files\n","from google.colab import files\n","\n","#Names Dataset \"data\"\n","data = files.upload()\n","\n","#Confirms Upload\n","for fn in data.keys():\n","  print('\\nUser uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(data[fn])))\n","\n","#Unzip Data\n","from zipfile import ZipFile\n","\n","with ZipFile('cnn_dataset.zip', 'r') as unzipped_data:\n","  unzipped_data.extractall('/content/data')\n","\n","print('\\nThe data was successfully unzipped! See the unzipped data below:')\n","\n","#Confirm that Data was Unzipped\n","!ls '/content/data'\n","\n","#Message If Folder Isn't Showing:\n","print('\\nIf you cannot see the folder in the directory list, hit the directory refresh button (middle button)')\n","\n","#Delete the Original .zip File\n","!rm cnn_dataset.zip\n","print('\\nThe original zip file has been deleted to free up space within the environment.')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-8efdac01-42d9-461e-82b7-79f5dc486099\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-8efdac01-42d9-461e-82b7-79f5dc486099\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-89241a745ce4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzipfile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cnn_dataset.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0munzipped_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0munzipped_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cnn_dataset.zip'"]}]},{"cell_type":"markdown","metadata":{"id":"cxpIv_UASmPu"},"source":["### Source for the following cells: https://www.tensorflow.org/tutorials/load_data/images"]},{"cell_type":"code","metadata":{"id":"C_PQsaGhGF28"},"source":["#Get the Dataset Working\n","import pathlib\n","dataset = '/content/data/cnn_dataset'\n","fire_data = pathlib.Path(dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aRQ-oE850sI2"},"source":["#Figure Out Number of Images in Dataset\n","image_count = len(list(fire_data.glob('*/*.jpg')))\n","print(image_count)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E_-Q-yzB1G4l"},"source":["#Create A Dataset\n","\n","#Define Parameters\n","batch_size = 10000\n","img_height = 64\n","img_width = 64"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SjJoBasIH3Tl"},"source":["#Create the Training Dataset\n","training_set = tf.keras.utils.image_dataset_from_directory(\n","    fire_data,\n","    validation_split = 0.25,\n","    subset = 'training',\n","    seed = 123,\n","    image_size = (img_height, img_width), \n","    batch_size=batch_size\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0VbHFPP1IYdv"},"source":["#Create the Testing Dataset\n","testing_set = tf.keras.utils.image_dataset_from_directory(\n","    fire_data,\n","    validation_split = 0.25,\n","    subset = 'validation',\n","    seed = 123,\n","    image_size = (img_height, img_width), \n","    batch_size=batch_size\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQe-dQjyVdy9"},"source":["#Create The Class Names\n","class_names = training_set.class_names\n","print(class_names)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D9QSG3q9I2Gl"},"source":["#Import MatPlotLib\n","import matplotlib.pyplot as plt\n","\n","#Plot First 9 Images from Training Dataset\n","plt.figure(figsize=(10, 10))\n","for images, labels in training_set.take(1):\n","  for i in range(9):\n","    ax = plt.subplot(3, 3, i + 1)\n","    plt.imshow(images[i].numpy().astype(\"uint8\"))\n","    plt.title(class_names[labels[i]])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JRBfJvPg5kgj"},"source":["# Convert Training Set To NumPy Arrays"]},{"cell_type":"code","metadata":{"id":"EGZsJkKDLxKd"},"source":["#Convert To NumPy Arrays (Training Set)\n","for image_batch, labels_batch in training_set:\n","\n","  #Convert the Training Dataset into NumPy Arrays\n","  x_train = np.array(image_batch)\n","  y_train = np.array(labels_batch)\n","\n","  #Confirm the Datatype and Shapes of \"x_train\"\n","  print(\"x_train:\")\n","  print(\"Image Class Type:\", type(x_train))\n","  print(\"Images Shape:\", x_train.shape)\n","\n","  #Confirm the Datatype and Shapes of \"y_train\"\n","  print(\"\\ny_train:\")\n","  print(\"Labels Class Type:\", type(y_train))\n","  print(\"Images Shape:\", y_train.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K_YNa8GA53Hg"},"source":["#Changing the Image Type from \"unit8\" to \"float32\"\n","x_train = x_train.astype('float32')/255\n","\n","#Changing the Label Type from \"unit8\" to \"int64\"\n","y_train = y_train.astype('int64')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fli06Fa3ACsp"},"source":["#Display First 9 Images of Training Set (To Verify Image and Label Match-Up)\n","\n","#Change Size of Images in Plot\n","plt.figure(figsize=(10, 10))\n","\n","#For Loop to Plot Images\n","for i in range(9):  \n","  \n","  #Define Subplot\n","  plt.subplot(3, 3, i+1)\n","\n","  #Plot Raw Image Pixel Data\n","  plt.imshow(x_train[i])\n","\n","  #Display Labels on Images\n","  plt.title(class_names[y_train[i]])\n","\n","#Show Images\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wLLhJwhHfGp2"},"source":["# Convert the Testing Set to NumPy Arrays"]},{"cell_type":"code","metadata":{"id":"ydyoJZEP7JRo"},"source":["#Convert To NumPy Arrays (Testing Set)\n","for image_batch, labels_batch in testing_set:\n","  \n","  #Convert Testing Set into NumPy Arrays\n","  x_test = np.array(image_batch)\n","  y_test = np.array(labels_batch)\n","\n","  #Confirm the Datatype and Shapes of \"x_test\"\n","  print(\"x_test:\")\n","  print(\"Image Class Type:\", type(x_test))\n","  print(\"Images Shape:\", x_test.shape)\n","\n","  #Confirm the Datatype and Shapes of \"y_test\"\n","  print(\"\\ny_test:\")\n","  print(\"Label Class Type:\", type(y_test))\n","  print(\"Label Shape:\", y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b3EXZwZ1gZak"},"source":["#Changing the Image Type from \"unit8\" to \"float32\"\n","x_test = x_test.astype('float32')/255\n","\n","#Changing the Label Type from \"unit8\" to \"int64\"\n","y_test = y_test.astype('int64')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PzED-R-RgcUh"},"source":["#Display First 9 Images of Testing Set (To Verify Image and Label Match-Up)\n","\n","#Change Size of Images in Plot\n","plt.figure(figsize=(10, 10))\n","\n","#For Loop to Plot Images\n","for i in range(9):  \n","  \n","  #Define Subplot\n","  plt.subplot(3, 3, i+1)\n","\n","  #Plot Raw Image Pixel Data\n","  plt.imshow(x_test[i])\n","\n","  #Display Labels on Images\n","  plt.title(class_names[y_test[i]])\n","\n","#Show Images\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Rle4muuJFmk"},"source":["# Grayscale The Images of the Whole Dataset"]},{"cell_type":"code","metadata":{"id":"WHiYGm4AJU0p"},"source":["#Grayscale Training and Testing Sets\n","grayscale_x_train = tf.image.rgb_to_grayscale(x_train[:])\n","grayscale_x_test = tf.image.rgb_to_grayscale(x_test[:])\n","\n","#Convert to NumPy Arrays and Check Shapes\n","grayscale_x_train = grayscale_x_train.numpy()\n","print('The Shape of the NumPy Training Set is: ', grayscale_x_train.shape)\n","\n","grayscale_x_test = grayscale_x_test.numpy()\n","print('The Shape of the NumPy Testing Set is: ', grayscale_x_test.shape)\n","\n","#Display the First Image of the Training Set\n","gray_image = tf.image.rgb_to_grayscale(x_train[1])\n","plt.imshow (tf.squeeze(gray_image), cmap = 'gray')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lTf8rV4jSHYC"},"source":["#The Model"]},{"cell_type":"code","metadata":{"id":"12APoUOoLKLh"},"source":["#Convolutional Neural Network\n","cnn = tf.keras.Sequential([\n","      \n","    #Convolutional Layer #1\n","    tf.keras.layers.Conv2D(filters = 64, kernel_size = (6, 6), strides = (1, 1), activation = 'relu', padding = 'same', input_shape = (64, 64, 1)),\n","\n","    #Pooling Layer #1\n","    tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2)),\n","\n","    #Convolutional Layer #2\n","    tf.keras.layers.Conv2D(filters = 32, kernel_size = (2, 2), activation = 'relu'),\n","\n","    #Pooling Layer #2\n","    tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2)),\n","\n","    #Flatten Output\n","    tf.keras.layers.Flatten(),\n","\n","    #Dense Layer #1\n","    tf.keras.layers.Dense(128, activation = 'relu'),\n","\n","    #Dense Layer #2\n","    tf.keras.layers.Dense(64, activation = 'relu'),\n","\n","    #Dense Layer #3\n","    tf.keras.layers.Dense(32, activation = 'relu'),\n","\n","    #Dense Layer #4\n","    tf.keras.layers.Dense(16, activation = 'relu'),\n","\n","    #Dense Layer #5\n","    tf.keras.layers.Dense(8, activation = 'relu'),\n","\n","    #Dense Layer #6\n","    tf.keras.layers.Dense(4, activation = 'softmax'),\n","\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iaI_Ho9LSR7o"},"source":["#Compile The Model\n","cnn.compile(optimizer = 'adam',\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics = ['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vxjyftjhSW_J"},"source":["#Model Summary\n","cnn.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JRI9K5elSbPo"},"source":["#Train The Model\n","EPOCHS = 5\n","history = cnn.fit(\n","    grayscale_x_train, y_train,\n","    batch_size = 12, epochs = EPOCHS, validation_split = 0.1, verbose = 1,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n3w_NvkaS0fO"},"source":["#Evaluate The Model\n","test_loss, test_acc = cnn.evaluate(grayscale_x_test, y_test, verbose = 1)\n","print('The Test Set Loss is: {0:0.4f} and the Test Set Accuracy is: {1:0.4}%'.format(test_loss, 100*test_acc))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yseD58tqTayE"},"source":["#Import MatPlotLib\n","import matplotlib.pyplot as plt\n","\n","#Define Variables\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","#Plot First Graph\n","plt.figure(figsize = (8, 8))\n","plt.subplot(2, 2, 1)\n","plt.plot(acc, label = \"Training Accuracy\")\n","plt.plot(val_acc, label = 'Validation Accuracy')\n","plt.legend(loc = 'lower right')\n","plt.ylabel('Accuracy')\n","plt.ylim([min(plt.ylim()), 1])\n","plt.title('Training and Validation Accuracy')\n","\n","#Plot the Second Graph\n","plt.subplot(2, 1, 2)\n","plt.plot(loss, label = 'Training Loss')\n","plt.plot(val_loss, label = 'Validation Loss')\n","plt.legend(loc = 'upper right')\n","plt.ylabel('Cross Entropy')\n","plt.ylim([0, 1.0])\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ExIb1sJtTnvv"},"source":["#Make Prediction\n","prediction = cnn.predict(grayscale_x_test[500].reshape(1, 64, 64, 1))\n","np_predict = np.argmax(prediction)\n","print(\"The model predicts the following image to be a member of Class {}\".format(np_predict) + \" which translates to {}\".format(class_names[np_predict]) + '.')\n","\n","#Show Image\n","plt.imshow(grayscale_x_test[500].reshape(64, 64))\n","plt.title(class_names[np_predict])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Code To Deploy Model Files - https://www.analyticsvidhya.com/blog/2021/04/easily-deploy-your-machine-learning-model-into-a-web-app-netlify/#h2_3"],"metadata":{"id":"GhSDLnkv8Edy"}},{"cell_type":"code","metadata":{"id":"FJlXT5JIT5Ni"},"source":["#Save model into a variable and save model\n","cnn_deployed = \"./cnn.h5\"\n","cnn.save(cnn_deployed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Import TensorFlow JS\n","!pip install tensorflowjs"],"metadata":{"id":"Vjhmmi5C-KJ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Convert using TensorFlowjs\n","!tensorflowjs_converter --input_format=keras '/content/cnn.h5' ./"],"metadata":{"id":"51e8VPyN-h45"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OkTOcrUkAFWb"},"execution_count":null,"outputs":[]}]}